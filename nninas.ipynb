{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii import model_wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelSpace(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): LayerChoice([Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1)), DepthwiseSeparableConv(\n",
       "    (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32)\n",
       "    (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )], label='model_1')\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, groups=in_ch)\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "\n",
    "\n",
    "@model_wrapper\n",
    "class ModelSpace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        # LayerChoice is used to select a layer between Conv2d and DwConv.\n",
    "        self.conv2 = nn.LayerChoice([\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            DepthwiseSeparableConv(32, 64)\n",
    "        ])\n",
    "        # ValueChoice is used to select a dropout rate.\n",
    "        # ValueChoice can be used as parameter of modules wrapped in `nni.retiarii.nn.pytorch`\n",
    "        # or customized modules wrapped with `@basic_unit`.\n",
    "        self.dropout1 = nn.Dropout(nn.ValueChoice([0.25, 0.5, 0.75]))  # choose dropout rate from 0.25, 0.5 and 0.75\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        feature = nn.ValueChoice([64, 128, 256])\n",
    "        self.fc1 = nn.Linear(9216, feature)\n",
    "        self.fc2 = nn.Linear(feature, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(self.conv2(x), 2)\n",
    "        x = torch.flatten(self.dropout1(x), 1)\n",
    "        x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "model_space = ModelSpace()\n",
    "model_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.nas.strategy as strategy\n",
    "import nni.nas.evaluator.pytorch.lightning as pl\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "transf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = MNIST('data/mnist', download=True, transform=transf)\n",
    "test_dataset = MNIST('data/mnist', download=True, train=False, transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Accuracy.__new__() missing 1 required positional argument: 'task'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluator \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mClassification(\n\u001b[1;32m      2\u001b[0m   \u001b[39m# Need to use `pl.DataLoader` instead of `torch.utils.data.DataLoader` here,\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m   \u001b[39m# or use `nni.trace` to wrap `torch.utils.data.DataLoader`.\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m   \n\u001b[1;32m      5\u001b[0m   train_dataloaders\u001b[39m=\u001b[39;49mpl\u001b[39m.\u001b[39;49mDataLoader(train_dataset, batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m),\n\u001b[1;32m      6\u001b[0m   val_dataloaders\u001b[39m=\u001b[39;49mpl\u001b[39m.\u001b[39;49mDataLoader(test_dataset, batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m),\n\u001b[1;32m      7\u001b[0m   \u001b[39m# Other keyword arguments passed to pytorch_lightning.Trainer.\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m   max_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m   gpus\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/evaluator/pytorch/lightning.py:371\u001b[0m, in \u001b[0;36mClassification.__init__\u001b[0;34m(self, criterion, learning_rate, weight_decay, optimizer, train_dataloaders, val_dataloaders, export_onnx, train_dataloader, **trainer_kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`train_dataloader` is deprecated and replaced with `train_dataloaders`.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    370\u001b[0m     train_dataloaders \u001b[39m=\u001b[39m train_dataloader\n\u001b[0;32m--> 371\u001b[0m module \u001b[39m=\u001b[39m ClassificationModule(criterion\u001b[39m=\u001b[39;49mcriterion, learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    372\u001b[0m                               weight_decay\u001b[39m=\u001b[39;49mweight_decay, optimizer\u001b[39m=\u001b[39;49moptimizer, export_onnx\u001b[39m=\u001b[39;49mexport_onnx)\n\u001b[1;32m    373\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(module, Trainer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_kwargs),\n\u001b[1;32m    374\u001b[0m                  train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/common/serializer.py:508\u001b[0m, in \u001b[0;36m_trace_cls.<locals>.wrapper.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m args, kwargs \u001b[39m=\u001b[39m _formulate_arguments(base\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m, args, kwargs, kw_only, is_class_init\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    506\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m     \u001b[39m# calling serializable object init to initialize the full object\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(symbol\u001b[39m=\u001b[39;49mbase, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, call_super\u001b[39m=\u001b[39;49mcall_super)\n\u001b[1;32m    509\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRecursionError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    510\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mRecursion error detected in initialization of wrapped object. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mDid you use `super(MyClass, self).__init__()` rather than `super().__init__()`? \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[39mRuntimeWarning\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/common/serializer.py:133\u001b[0m, in \u001b[0;36mSerializableObject.__init__\u001b[0;34m(self, symbol, args, kwargs, call_super)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_nni_call_super\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m call_super\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m call_super:\n\u001b[1;32m    132\u001b[0m     \u001b[39m# call super means that the serializable object is by itself an object of the target class\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    134\u001b[0m         \u001b[39m*\u001b[39;49m[_argument_processor(arg) \u001b[39mfor\u001b[39;49;00m arg \u001b[39min\u001b[39;49;00m args],\n\u001b[1;32m    135\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{kw: _argument_processor(arg) \u001b[39mfor\u001b[39;49;00m kw, arg \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems()}\n\u001b[1;32m    136\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/evaluator/pytorch/lightning.py:308\u001b[0m, in \u001b[0;36mClassificationModule.__init__\u001b[0;34m(self, criterion, learning_rate, weight_decay, optimizer, export_onnx)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, criterion: Type[nn\u001b[39m.\u001b[39mModule] \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss,\n\u001b[1;32m    304\u001b[0m              learning_rate: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m,\n\u001b[1;32m    305\u001b[0m              weight_decay: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m,\n\u001b[1;32m    306\u001b[0m              optimizer: Type[optim\u001b[39m.\u001b[39mOptimizer] \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam,\n\u001b[1;32m    307\u001b[0m              export_onnx: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 308\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(criterion, {\u001b[39m'\u001b[39;49m\u001b[39macc\u001b[39;49m\u001b[39m'\u001b[39;49m: AccuracyWithLogits},\n\u001b[1;32m    309\u001b[0m                      learning_rate\u001b[39m=\u001b[39;49mlearning_rate, weight_decay\u001b[39m=\u001b[39;49mweight_decay, optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    310\u001b[0m                      export_onnx\u001b[39m=\u001b[39;49mexport_onnx)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/evaluator/pytorch/lightning.py:224\u001b[0m, in \u001b[0;36mSupervisedLearningModule.__init__\u001b[0;34m(self, criterion, metrics, learning_rate, weight_decay, optimizer, export_onnx)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion \u001b[39m=\u001b[39m criterion()\n\u001b[1;32m    223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n\u001b[0;32m--> 224\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleDict({name: \u001b[39mcls\u001b[39;49m() \u001b[39mfor\u001b[39;49;00m name, \u001b[39mcls\u001b[39;49m \u001b[39min\u001b[39;49;00m metrics\u001b[39m.\u001b[39;49mitems()})\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m export_onnx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m export_onnx \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexport_onnx \u001b[39m=\u001b[39m Path(os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mNNI_OUTPUT_DIR\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodel.onnx\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/evaluator/pytorch/lightning.py:224\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion \u001b[39m=\u001b[39m criterion()\n\u001b[1;32m    223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n\u001b[0;32m--> 224\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleDict({name: \u001b[39mcls\u001b[39;49m() \u001b[39mfor\u001b[39;00m name, \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m metrics\u001b[39m.\u001b[39mitems()})\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m export_onnx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m export_onnx \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexport_onnx \u001b[39m=\u001b[39m Path(os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mNNI_OUTPUT_DIR\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodel.onnx\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Accuracy.__new__() missing 1 required positional argument: 'task'"
     ]
    }
   ],
   "source": [
    "evaluator = pl.Classification(\n",
    "  # Need to use `pl.DataLoader` instead of `torch.utils.data.DataLoader` here,\n",
    "  # or use `nni.trace` to wrap `torch.utils.data.DataLoader`.\n",
    "  \n",
    "  train_dataloaders=pl.DataLoader(train_dataset, batch_size=100),\n",
    "  val_dataloaders=pl.DataLoader(test_dataset, batch_size=100),\n",
    "  # Other keyword arguments passed to pytorch_lightning.Trainer.\n",
    "  max_epochs=10,\n",
    "  gpus=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_strategy = strategy.DARTS()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
