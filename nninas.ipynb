{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import nni\n",
    "import nni.nas.nn.pytorch as nn_\n",
    "import nni.nas.nn.pytorch._layers as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %\n",
    "# class DepthwiseSeparableConv(torch.nn.Module):\n",
    "#     def __init__(self, in_ch, out_ch):\n",
    "#         super().__init__()\n",
    "#         self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, groups=in_ch)\n",
    "#         self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.pointwise(self.depthwise(x))\n",
    "\n",
    "\n",
    "class MyModelSpace(nn_.ModelSpace):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        # LayerChoice is used to select a layer between Conv2d and DwConv.\n",
    "        self.conv2 = nn_.LayerChoice([\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.Conv2d(32, 64, 3, 2)\n",
    "            # DepthwiseSeparableConv(32, 64)\n",
    "        ],label='conv2')\n",
    "        self.dropout1 = nn.Dropout(0.5)#nni.choice(label='dropout1',choices=[0.25, 0.5, 0.75]))  # choose dropout rate from 0.25, 0.5 and 0.75\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        feature = 512 #nni.choice(label='feature',choices=[64, 128, 256])\n",
    "        self.fc1 = nn.Linear(9216, feature)\n",
    "        self.fc2 = nn.Linear(feature, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(self.conv2(x), 2)\n",
    "        x = torch.flatten(self.dropout1(x), 1)\n",
    "        x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "model_space = MyModelSpace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %\n",
    "import nni.nas.strategy as strategy\n",
    "import nni.nas.evaluator.pytorch.lightning as pl\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def train_epoch(model, device, train_loader, optimizer, epoch):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test_epoch(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          correct, len(test_loader.dataset), accuracy))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_model(model):\n",
    "    # By v3.0, the model will be instantiated by default.\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    transf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_loader = pl.DataLoader(MNIST('data/mnist', download=True, transform=transf), batch_size=100),\n",
    "    test_loader = pl.DataLoader(MNIST('data/mnist', download=True, train=False, transform=transf), batch_size=100),\n",
    "\n",
    "    for epoch in range(3):\n",
    "        # train the model for one epoch\n",
    "        train_epoch(model, device, train_loader, optimizer, epoch)\n",
    "        # test the model for one epoch\n",
    "        accuracy = test_epoch(model, device, test_loader)\n",
    "        # call report intermediate result. Result can be float or dict\n",
    "        nni.report_intermediate_result(accuracy)\n",
    "\n",
    "    # report final test result\n",
    "    nni.report_final_result(accuracy)\n",
    "\n",
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "evaluator = FunctionalEvaluator(evaluate_model)\n",
    "\n",
    "# %\n",
    "exploration_strategy = strategy.DARTS()\n",
    "# exploration_strategy = strategy.Random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-24 15:53:45] \u001b[32mConfig is not provided. Will try to infer.\u001b[0m\n",
      "[2023-07-24 15:53:45] \u001b[32mStrategy is found to be a one-shot strategy. Setting execution engine to \"sequential\" and format to \"raw\".\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from nni.nas.experiment import NasExperimentConfig\n",
    "config = NasExperimentConfig.default(model_space, evaluator, exploration_strategy)\n",
    "# config = NasExperimentConfig()\n",
    "# config.training_service.platform = 'local'\n",
    "# config.training_service.use_active_gpu = True\n",
    "config.trial_gpu_number = 0\n",
    "config.max_trial_number = 3   # spawn 3 trials at most\n",
    "config.trial_concurrency = 1  # will run 1 trial concurrently\n",
    "# config.execution_engine.name = 'sequential'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %\n",
    "from nni.nas.experiment import NasExperiment\n",
    "exp = NasExperiment(model_space, evaluator, exploration_strategy, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-24 15:53:51] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2023-07-24 15:53:51] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2023-07-24 15:53:51] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Evaluator needs to be a lightning evaluator to make one-shot strategy work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m exp\u001b[39m.\u001b[39;49mrun(\u001b[39m8085\u001b[39;49m,\u001b[39mTrue\u001b[39;49;00m,\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/experiment.py:236\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self, port, wait_completion, debug)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, port: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m8080\u001b[39m, wait_completion: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, debug: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[39m    Run the experiment.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39m    Otherwise, return ``True`` when experiment done; or return ``False`` when experiment failed.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_impl(port, wait_completion, debug)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/experiment.py:205\u001b[0m, in \u001b[0;36mExperiment._run_impl\u001b[0;34m(self, port, wait_completion, debug)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_impl\u001b[39m(\u001b[39mself\u001b[39m, port: \u001b[39mint\u001b[39m, wait_completion: \u001b[39mbool\u001b[39m, debug: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart(port, debug)\n\u001b[1;32m    206\u001b[0m         \u001b[39mif\u001b[39;00m wait_completion:\n\u001b[1;32m    207\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_completion()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/experiment/experiment.py:270\u001b[0m, in \u001b[0;36mNasExperiment.start\u001b[0;34m(self, port, debug, run_mode)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_without_nni_manager()\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mcreate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresume\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m--> 270\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_start_engine_and_strategy()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/experiment/experiment.py:217\u001b[0m, in \u001b[0;36mNasExperiment._start_engine_and_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecution_engine_factory(config\u001b[39m.\u001b[39mexecution_engine)\n\u001b[1;32m    216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_model_space \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecutable_model_factory(config\u001b[39m.\u001b[39mmodel_format)\n\u001b[0;32m--> 217\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49minitialize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_model_space, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine)\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mresume\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_checkpoint()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/strategy/base.py:140\u001b[0m, in \u001b[0;36mStrategy.initialize\u001b[0;34m(self, model_space, engine)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_space \u001b[39m=\u001b[39m model_space\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m engine\n\u001b[0;32m--> 140\u001b[0m model_space \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(model_space, engine)\n\u001b[1;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_status \u001b[39m=\u001b[39m StrategyStatus\u001b[39m.\u001b[39mINITIALIZED\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m model_space\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/oneshot/pytorch/strategy.py:322\u001b[0m, in \u001b[0;36mOneShotStrategy._initialize\u001b[0;34m(self, model_space, engine)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39m# Type validation inside.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutate_model(cast(ModelSpace, model_space\u001b[39m.\u001b[39mmodel_space))\n\u001b[0;32m--> 322\u001b[0m evaluator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutate_evaluator(cast(Lightning, model_space\u001b[39m.\u001b[39;49mevaluator))\n\u001b[1;32m    324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutated_model_space \u001b[39m=\u001b[39m RawFormatModelSpace(model, evaluator)\n\u001b[1;32m    325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutated_model_space\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m ModelStatus\u001b[39m.\u001b[39mFrozen\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/oneshot/pytorch/strategy.py:283\u001b[0m, in \u001b[0;36mOneShotStrategy.mutate_evaluator\u001b[0;34m(self, evaluator)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Mutate the evaluator to the one used in one-shot.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \n\u001b[1;32m    273\u001b[0m \u001b[39mSpecifically, it:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mThe mutated evaluator.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(evaluator, Lightning):\n\u001b[0;32m--> 283\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mEvaluator needs to be a lightning evaluator to make one-shot strategy work.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(evaluator, Mutable) \u001b[39mand\u001b[39;00m evaluator\u001b[39m.\u001b[39msimplify():\n\u001b[1;32m    285\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mEvaluator cannot contain any mutable parameters for one-shot strategy.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Evaluator needs to be a lightning evaluator to make one-shot strategy work."
     ]
    }
   ],
   "source": [
    "exp.run(8085,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_dict in exp.export_data():\n",
    "    print(model_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
