{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import nni\n",
    "import nni.nas.nn.pytorch as nn_\n",
    "import nni.nas.nn.pytorch._layers as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %\n",
    "# class DepthwiseSeparableConv(torch.nn.Module):\n",
    "#     def __init__(self, in_ch, out_ch):\n",
    "#         super().__init__()\n",
    "#         self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, groups=in_ch)\n",
    "#         self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.pointwise(self.depthwise(x))\n",
    "\n",
    "\n",
    "class MyModelSpace(nn_.ModelSpace):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        # LayerChoice is used to select a layer between Conv2d and DwConv.\n",
    "        self.conv2 = nn_.LayerChoice([\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.Conv2d(32, 64, 3, 2)\n",
    "            # DepthwiseSeparableConv(32, 64)\n",
    "        ],label='conv2')\n",
    "        self.dropout1 = nn.Dropout(nni.choice(label='dropout1',choices=[0.25, 0.5, 0.75]))  # choose dropout rate from 0.25, 0.5 and 0.75\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        feature = nni.choice(label='feature',choices=[64, 128, 256])\n",
    "        self.fc1 = nn.Linear(9216, feature)\n",
    "        self.fc2 = nn.Linear(feature, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(self.conv2(x), 2)\n",
    "        x = torch.flatten(self.dropout1(x), 1)\n",
    "        x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "model_space = MyModelSpace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %\n",
    "import nni.nas.strategy as strategy\n",
    "import nni.nas.evaluator.pytorch.lightning as pl\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "# transf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# train_dataset = MNIST('data/mnist', download=True, transform=transf)\n",
    "# test_dataset = MNIST('data/mnist', download=True, train=False, transform=transf)\n",
    "\n",
    "# # %\n",
    "# evaluator = pl.Classification(\n",
    "#   # Need to use `pl.DataLoader` instead of `torch.utils.data.DataLoader` here,\n",
    "#   # or use `nni.trace` to wrap `torch.utils.data.DataLoader`.\n",
    "  \n",
    "#   train_dataloaders=pl.DataLoader(train_dataset, batch_size=100),\n",
    "#   val_dataloaders=pl.DataLoader(test_dataset, batch_size=100),\n",
    "#   # Other keyword arguments passed to pytorch_lightning.Trainer.\n",
    "#   max_epochs=10,\n",
    "# )\n",
    "\n",
    "def train_epoch(model, device, train_loader, optimizer, epoch):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test_epoch(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          correct, len(test_loader.dataset), accuracy))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_model(model):\n",
    "    # By v3.0, the model will be instantiated by default.\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    transf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_loader = pl.DataLoader(MNIST('data/mnist', download=True, transform=transf), batch_size=100),\n",
    "    test_loader = pl.DataLoader(MNIST('data/mnist', download=True, train=False, transform=transf), batch_size=100),\n",
    "\n",
    "    for epoch in range(3):\n",
    "        # train the model for one epoch\n",
    "        train_epoch(model, device, train_loader, optimizer, epoch)\n",
    "        # test the model for one epoch\n",
    "        accuracy = test_epoch(model, device, test_loader)\n",
    "        # call report intermediate result. Result can be float or dict\n",
    "        nni.report_intermediate_result(accuracy)\n",
    "\n",
    "    # report final test result\n",
    "    nni.report_final_result(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-20 18:20:03] \u001b[32mConfig is not provided. Will try to infer.\u001b[0m\n",
      "[2023-07-20 18:20:03] \u001b[32mStrategy is found to be a one-shot strategy. Setting execution engine to \"sequential\" and format to \"raw\".\u001b[0m\n",
      "[2023-07-20 18:20:03] \u001b[32mModel space is found to be a one-shot supernet. Setting execution engine to \"sequential\" and format to \"raw\" to preserve the weights.\u001b[0m\n",
      "[2023-07-20 18:20:03] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "LocalConfig: please set use_active_gpu to True if your system has GUI, or set it to False if the computer runs multiple experiments concurrently.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# exp.config.max_trial_number = 3   # spawn 3 trials at most\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# exp.config.trial_concurrency = 1  # will run 1 trial concurrently\u001b[39;00m\n\u001b[1;32m     15\u001b[0m exp\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mtrial_gpu_number \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 17\u001b[0m exp\u001b[39m.\u001b[39;49mrun(\u001b[39m8085\u001b[39;49m,\u001b[39mTrue\u001b[39;49;00m,\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/experiment.py:236\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self, port, wait_completion, debug)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, port: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m8080\u001b[39m, wait_completion: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, debug: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[39m    Run the experiment.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39m    Otherwise, return ``True`` when experiment done; or return ``False`` when experiment failed.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_impl(port, wait_completion, debug)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/experiment.py:205\u001b[0m, in \u001b[0;36mExperiment._run_impl\u001b[0;34m(self, port, wait_completion, debug)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_impl\u001b[39m(\u001b[39mself\u001b[39m, port: \u001b[39mint\u001b[39m, wait_completion: \u001b[39mbool\u001b[39m, debug: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart(port, debug)\n\u001b[1;32m    206\u001b[0m         \u001b[39mif\u001b[39;00m wait_completion:\n\u001b[1;32m    207\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_completion()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/nas/experiment/experiment.py:257\u001b[0m, in \u001b[0;36mNasExperiment.start\u001b[0;34m(self, port, debug, run_mode)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m run_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m RunMode\u001b[39m.\u001b[39mDetach:\n\u001b[1;32m    255\u001b[0m     atexit\u001b[39m.\u001b[39mregister(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_start_logging(debug)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nni_manager_required():\n\u001b[1;32m    260\u001b[0m     _logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mStarting NNI manager...\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/experiment.py:110\u001b[0m, in \u001b[0;36mExperiment._start_logging\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_start_logging\u001b[39m(\u001b[39mself\u001b[39m, debug: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mcanonical_copy()\n\u001b[1;32m    112\u001b[0m     log_file \u001b[39m=\u001b[39m Path(config\u001b[39m.\u001b[39mexperiment_working_directory, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid, \u001b[39m'\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexperiment.log\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m     log_file\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/config/base.py:167\u001b[0m, in \u001b[0;36mConfigBase.canonical_copy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m canon \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    166\u001b[0m canon\u001b[39m.\u001b[39m_canonicalize([])\n\u001b[0;32m--> 167\u001b[0m canon\u001b[39m.\u001b[39;49m_validate_canonical()\n\u001b[1;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m canon\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/config/experiment_config.py:167\u001b[0m, in \u001b[0;36mExperimentConfig._validate_canonical\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_canonical\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_validate_canonical()\n\u001b[1;32m    169\u001b[0m     space_cnt \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_space \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_space_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_annotation \u001b[39mand\u001b[39;00m space_cnt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/config/base.py:240\u001b[0m, in \u001b[0;36mConfigBase._validate_canonical\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mfor\u001b[39;00m field \u001b[39min\u001b[39;00m utils\u001b[39m.\u001b[39mfields(\u001b[39mself\u001b[39m):\n\u001b[1;32m    239\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, field\u001b[39m.\u001b[39mname)\n\u001b[0;32m--> 240\u001b[0m     _recursive_validate_child(value)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/config/base.py:279\u001b[0m, in \u001b[0;36m_recursive_validate_child\u001b[0;34m(child)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recursive_validate_child\u001b[39m(child):\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(child, ConfigBase):\n\u001b[0;32m--> 279\u001b[0m         child\u001b[39m.\u001b[39;49m_validate_canonical()\n\u001b[1;32m    280\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(child, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m         \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m child:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/nni/experiment/config/training_services/local.py:44\u001b[0m, in \u001b[0;36mLocalConfig._validate_canonical\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m utils\u001b[39m.\u001b[39mvalidate_gpu_indices(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgpu_indices)\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrial_gpu_number \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_active_gpu \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mLocalConfig: please set use_active_gpu to True if your system has GUI, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     46\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mor set it to False if the computer runs multiple experiments concurrently.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrial_gpu_number \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_trial_number_per_gpu \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mLocalConfig: max_trial_number_per_gpu does not work without trial_gpu_number\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: LocalConfig: please set use_active_gpu to True if your system has GUI, or set it to False if the computer runs multiple experiments concurrently."
     ]
    }
   ],
   "source": [
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "evaluator = FunctionalEvaluator(evaluate_model)\n",
    "\n",
    "# %\n",
    "exploration_strategy = strategy.DARTS()\n",
    "# exploration_strategy = strategy.Random()\n",
    "\n",
    "# %\n",
    "from nni.nas.experiment import NasExperiment\n",
    "exp = NasExperiment(model_space, evaluator, exploration_strategy)\n",
    "exp.config.training_service.use_active_gpu = True\n",
    "\n",
    "# exp.config.max_trial_number = 3   # spawn 3 trials at most\n",
    "# exp.config.trial_concurrency = 1  # will run 1 trial concurrently\n",
    "exp.config.trial_gpu_number = 1\n",
    "\n",
    "exp.run(8085,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_dict in exp.export_data():\n",
    "    print(model_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
